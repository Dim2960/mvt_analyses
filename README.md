# Person Detection and Tracking with Pose Estimation

## ğŸŒŸ Description

Ce projet combine YOLO pour la dÃ©tection de personnes, DeepSORT pour le suivi des personnes, et MediaPipe pour la dÃ©tection de poses. Il traite une vidÃ©o en dÃ©tectant, suivant et annotant les personnes et les poses, puis enregistre le rÃ©sultat dans un fichier vidÃ©o.

Dans un cas d'usage, l'objectif serait de rÃ©aliser un suivi prÃ©cis des combattants de judo dans une vidÃ©o, afin de dÃ©tecter et d'analyser les mouvements et techniques qu'ils exÃ©cutent. Ce projet vise Ã  fournir des informations dÃ©taillÃ©es sur les actions des judokas, permettant ainsi une analyse statistique des techniques et de la performance globale lors d'un championnat, par exemple.

ğŸš¨ **Attention Limitation :** le nombre de personne dÃ©tectÃ© en terme de position n'est pas ajustable automatiquement est un max doit Ãªtre defini dans les paramÃ¨tres de mediapipe.landmarker

## ğŸ’¡ FonctionnalitÃ©s

- DÃ©tection de personne avec YOLO.
- Suivi avec DeepSORT.
- DÃ©tection de poses avec MediaPipe.
- Annotation des personnes et des poses sur les frames vidÃ©o.
- Enregistrement de la vidÃ©o annotÃ©e.

## ğŸ’ª PrÃ©requis

- Python 3.10.9
- OpenCV
- NumPy
- Ultralytics YOLO
- DeepSORT
- Supervision
- MediaPipe

## ğŸ›  Installation

1. Clonez le dÃ©pÃ´t :

    ```bash
    git clone https://github.com/Dim2960/mvt_analyses.git
    cd mvt_analyses
    ```

2. Installez les dÃ©pendances :

    ```bash
    pip install -r requirements.txt
    ```

## ğŸ” Utilisation

1. Placez votre vidÃ©o source dans le dossier \`videos\` et nommez-la \`test_17.mp4\`.

2. ExÃ©cutez le script principal :

    ```bash
    python main.py
    ```

3. Le script traitera la vidÃ©o et enregistrera le rÃ©sultat dans le dossier \`videos\` avec le prÃ©fixe \`result_\`.

## âš™ï¸ Configuration

Vous pouvez configurer les paramÃ¨tres des modÃ¨les et du tracker en modifiant les dictionnaires \`MODEL_PARAMS\` et \`TRACKER_PARAMS\` dans le script principal.

Cette exemple est optimisÃ© pour un combat de judo.

### ParamÃ¨tres des modÃ¨les

```python
MODEL_PARAMS = {
    'yolo_model_path': 'model/yolo11x.pt',
    'pose_model_path': 'model/pose_landmarker_lite.task',
    'running_mode': RunningMode.VIDEO,
    'num_poses': 3,
    'min_pose_detection_confidence': 0.75,
    'min_pose_presence_confidence': 0.5,
    'min_tracking_confidence': 0.95,
    'output_segmentation_masks': True
}
```

### ParamÃ¨tres du tracker

```python
TRACKER_PARAMS = {
    'max_age': 400,
    'n_init': 50,
    'max_cosine_distance': 0.17,
    'nn_budget': 300,
    'override_track_class': 0,
    'half': False,
    'bgr': True,
    'max_iou_distance': 0.9
}
```

## ğŸ—ƒï¸ Structure du projet

```
mvt_analyses/
â”‚
â”œâ”€â”€ videos/
â”‚   â”œâ”€â”€ test_17.mp4
â”‚   â”œâ”€â”€ test_xx.mp4
â”‚   â”œâ”€â”€ result_test_17.mp4
â”‚   â”œâ”€â”€ result_test_xx.mp4
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ yolo11x.pt
â”‚   â”œâ”€â”€ pose_landmarker_lite.task
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ detection.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ LICENCE
â””â”€â”€ README.md
```

## ğŸ“š Licence

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

## ğŸ™ Remerciements

- [Ultralytics YOLO](https://github.com/ultralytics)
- [DeepSORT](https://github.com/nwojke/deep_sort)
- [MediaPipe](https://ai.google.dev/edge/mediapipe/solutions/)

## ğŸŒ Contribution

N'hÃ©sitez pas Ã  contribuer au projet en soumettant des pull requests ou en signalant des bugs.

---